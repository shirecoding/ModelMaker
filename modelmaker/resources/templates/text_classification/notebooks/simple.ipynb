{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification with an RNN\n",
    "\n",
    "Referenced from https://www.tensorflow.org/tutorials/text/text_classification_rnn\n",
    "\n",
    "This text classification tutorial trains a recurrent neural network on the IMDB large movie review dataset for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "``` bash\n",
    "# install dataset\n",
    "pip3 install -q tensorflow_datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:\n",
      "\n",
      "Large Movie Review Dataset.\n",
      "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n",
      "\n",
      "Features:\n",
      "\n",
      "FeaturesDict({\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "    'text': Text(shape=(), dtype=tf.string),\n",
      "})\n",
      "\n",
      "Train Set:\n",
      "\n",
      "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n",
      "\n",
      "25000 train samples and 25000 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "print(f\"Description:\\n\\n{info.description}\\n\")\n",
    "print(f\"Features:\\n\\n{info.features}\\n\")\n",
    "print(f\"Train Element:\\n\\n{train_dataset.element_spec}\\n\")\n",
    "print(f\"{len(train_dataset)} train samples and {len(test_dataset)} samples\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print('text: ', example.numpy())\n",
    "    print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# shuffle and batch data\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 text and 64 in a batch\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print(f\"{len(example.numpy())} text and {len(label.numpy())} in a batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "\n",
    "# encode text data\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary: ['' '[UNK]' 'the' 'and' 'a']\n"
     ]
    }
   ],
   "source": [
    "# get vocabulary using encoder\n",
    "vocab = np.array(encoder.get_vocabulary())\n",
    "print(f\"vocabulary: {vocab[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      " b\"I saw this film as it was the second feature on a disc containing the previously banned Video Nasty 'Blood Rites'. As Blood Rites was entirely awful, I really wasn't expecting much from this film; but actually, it would seem that trash director Andy Milligan has outdone himself this time as Seeds of Sin tops Blood Rites in style and stands tall as a more than adequate slice of sick sixties sexploitation. The plot is actually quite similar to Blood Rites, as we focus on a dysfunctional family unit, and of course; there is an inheritance at stake. The film is shot in black and white, and the look and feel of it reminded me a lot of the trash classic 'The Curious Dr Humpp'. There's barely any gore on display, and the director seems keener to focus on sex, with themes of incest and hatred seeping through. The acting is typically trashy, but most of the women get to appear nude at some point and despite a poor reputation, director Andy Milligan actually seems to have an eye for this sort of thing, as many of the sequences in this film are actually quite beautiful. The plot is paper thin, and most of the film is filler; but the music is catchy, and the director also does a surprisingly good job with the sex scenes themselves, as most are somewhat erotic. Overall, this is not a great film; but it's likely to appeal to the cult fan, and gets a much higher recommendation than the better known and lower quality 'Blood Rites'.\"\n",
      "\n",
      "tokenize\n",
      " [ 10 208  11  20  15   9  14   2 326 812  21   4   1   1   2   1   1 393\n",
      "   1 535   1  15 535   1  14   1 381  10  63 268 982  73  36  11  20  19\n",
      " 157   9  59 289  12   1 172   1   1  44   1 304  11  62  15   1   5   1\n",
      "   1 535   1   8 430   3   1   1  15   4  52  71   1   1   5   1   1   1\n",
      "   2 114   7 157 176 712   6 535   1  15  72   1  21   4   1 222   1   3\n",
      "   5 259  48   7  34   1  31   1   2  20   7 319   8 323   3 447   3   2\n",
      " 163   3 232   5   9   1  70   4 169   5   2   1 350   2   1 881   1 213\n",
      "   1  99 630  21   1   3   2 172 181   1   6   1  21 392  17   1   5   1\n",
      "   3   1   1 141   2 112   7   1   1  19  88   5   2 362  76   6 945   1\n",
      "  31  47 215   3 450   4 330   1 172   1   1 157 181   6  26  34 826  16\n",
      "  11 425   5 151  15 106   5   2 832   8  11  20  24 157 176 300   2 114\n",
      "   7   1   1   3  88   5   2  20   7   1  19   2 223   7   1   3   2 172\n",
      "  79 121   4   1  50 286  17   2 392 137 520  15  88  24 610   1 432  11\n",
      "   7  22   4  85  20  19  30   1   6   1   6   2   1 331   3 202   4  73\n",
      "   1   1  71   2 125 617   3   1 496 535   1]\n",
      "\n",
      "recovered\n",
      " ['i' 'saw' 'this' 'film' 'as' 'it' 'was' 'the' 'second' 'feature' 'on' 'a'\n",
      " '[UNK]' '[UNK]' 'the' '[UNK]' '[UNK]' 'video' '[UNK]' 'blood' '[UNK]'\n",
      " 'as' 'blood' '[UNK]' 'was' '[UNK]' 'awful' 'i' 'really' 'wasnt'\n",
      " 'expecting' 'much' 'from' 'this' 'film' 'but' 'actually' 'it' 'would'\n",
      " 'seem' 'that' '[UNK]' 'director' '[UNK]' '[UNK]' 'has' '[UNK]' 'himself'\n",
      " 'this' 'time' 'as' '[UNK]' 'of' '[UNK]' '[UNK]' 'blood' '[UNK]' 'in'\n",
      " 'style' 'and' '[UNK]' '[UNK]' 'as' 'a' 'more' 'than' '[UNK]' '[UNK]' 'of'\n",
      " '[UNK]' '[UNK]' '[UNK]' 'the' 'plot' 'is' 'actually' 'quite' 'similar'\n",
      " 'to' 'blood' '[UNK]' 'as' 'we' '[UNK]' 'on' 'a' '[UNK]' 'family' '[UNK]'\n",
      " 'and' 'of' 'course' 'there' 'is' 'an' '[UNK]' 'at' '[UNK]' 'the' 'film'\n",
      " 'is' 'shot' 'in' 'black' 'and' 'white' 'and' 'the' 'look' 'and' 'feel'\n",
      " 'of' 'it' '[UNK]' 'me' 'a' 'lot' 'of' 'the' '[UNK]' 'classic' 'the'\n",
      " '[UNK]' 'dr' '[UNK]' 'theres' '[UNK]' 'any' 'gore' 'on' '[UNK]' 'and'\n",
      " 'the' 'director' 'seems' '[UNK]' 'to' '[UNK]' 'on' 'sex' 'with' '[UNK]'\n",
      " 'of' '[UNK]' 'and' '[UNK]' '[UNK]' 'through' 'the' 'acting' 'is' '[UNK]'\n",
      " '[UNK]' 'but' 'most' 'of' 'the' 'women' 'get' 'to' 'appear' '[UNK]' 'at'\n",
      " 'some' 'point' 'and' 'despite' 'a' 'poor' '[UNK]' 'director' '[UNK]'\n",
      " '[UNK]' 'actually' 'seems' 'to' 'have' 'an' 'eye' 'for' 'this' 'sort'\n",
      " 'of' 'thing' 'as' 'many' 'of' 'the' 'sequences' 'in' 'this' 'film' 'are'\n",
      " 'actually' 'quite' 'beautiful' 'the' 'plot' 'is' '[UNK]' '[UNK]' 'and'\n",
      " 'most' 'of' 'the' 'film' 'is' '[UNK]' 'but' 'the' 'music' 'is' '[UNK]'\n",
      " 'and' 'the' 'director' 'also' 'does' 'a' '[UNK]' 'good' 'job' 'with'\n",
      " 'the' 'sex' 'scenes' 'themselves' 'as' 'most' 'are' 'somewhat' '[UNK]'\n",
      " 'overall' 'this' 'is' 'not' 'a' 'great' 'film' 'but' 'its' '[UNK]' 'to'\n",
      " '[UNK]' 'to' 'the' '[UNK]' 'fan' 'and' 'gets' 'a' 'much' '[UNK]' '[UNK]'\n",
      " 'than' 'the' 'better' 'known' 'and' '[UNK]' 'quality' 'blood' '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "# tokenize string with encoder\n",
    "for text, label in train_dataset.take(1):\n",
    "    original = text.numpy()[0]\n",
    "    tokenized = encoder(original).numpy()\n",
    "    recovered = vocab[tokenized]\n",
    "    print(\"original\\n\", original)\n",
    "    print(\"\\ntokenize\\n\", tokenized)\n",
    "    print(\"\\nrecovered\\n\", recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True\n",
    "    ),\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64)\n",
    "    ),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01171657]\n",
      "[-0.01171658]\n"
     ]
    }
   ],
   "source": [
    "# predict on a sample text without padding.\n",
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])\n",
    "\n",
    "# predict on a sample text with padding\n",
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     epochs=10,\n",
    "#     validation_data=test_dataset, \n",
    "#     validation_steps=30\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 80s 200ms/step - loss: 0.6905 - accuracy: 0.5000\n",
      "Test Loss: 0.6905168890953064\n",
      "Test Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = ['The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.', 'asd']\n",
    "np.array([*sample_text]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
